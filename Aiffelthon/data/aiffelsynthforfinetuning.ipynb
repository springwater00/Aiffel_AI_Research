{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for synthesizer sound\n",
    "\n",
    "</br>\n",
    "\n",
    "- This section is designed to create a synthesizer dataset using a random sound sample (wav).\n",
    "\n",
    "- It assumes that the raw sound sample file name includes the artist name, instrument, and a descriptive word for the sound texture.\n",
    "\n",
    "- The 'Creating CSV from wav file' code section explains how to extract the file name from the wav file and generate a CSV file.\n",
    "\n",
    "- The 'Wav to JSON' code section describes how to create a JSON file from the CSV. The information in the JSON file will be used alongside the wav file when it is input into the deep learning model (In this case, we used the LAION AI - CLAP Model).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating CSV from wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "\n",
    "def parse_filename(filename):\n",
    "    split_name = filename.split('_')\n",
    "    artist = split_name[0].lower()\n",
    "    instrument = None\n",
    "    key = None\n",
    "    is_one_shot = False\n",
    "    description = []\n",
    "    etc = []\n",
    "\n",
    "    for part in split_name[1:]:\n",
    "        if part.lower() in ['lead', 'pluck', 'bass']:\n",
    "            instrument = part.lower()\n",
    "        elif 'one' in part.lower() and 'shot' in part.lower():\n",
    "            is_one_shot = True\n",
    "        elif any(c.isdigit() for c in part) or part.lower() in ['c', 'd', 'e', 'f', 'g', 'a', 'b', 'maj', 'min']:\n",
    "            key = part.lower()\n",
    "        else:\n",
    "            etc.append(part)\n",
    "\n",
    "    if instrument is None:\n",
    "        file_without_ext = os.path.splitext(filename)[0]\n",
    "        last_part = file_without_ext.split('_')[-1].lower()\n",
    "        if last_part in ['lead', 'pluck', 'bass']:\n",
    "            instrument = last_part\n",
    "            if instrument in etc:\n",
    "                etc.remove(instrument)\n",
    "\n",
    "    etc = ' '.join(etc).replace('.wav', '')\n",
    "    \n",
    "    exclude_words = ['synth', 'c', 'd', 'e', 'f', 'g', 'a', 'b', \n",
    "                     'C','D','E','F','G','A','B',\n",
    "                     'cmaj', 'dmaj', 'emaj', 'fmaj', 'gmaj', 'amaj', 'bmaj', \n",
    "                     'cmin', 'dmin', 'emin', 'fmin', 'gmin', 'amin', 'bmin', \n",
    "                     'wav', '.', 'oneshot', 'one shot', 'one_shot', '_one_shot_', \n",
    "                     'pad', 'pluck', 'lead', 'bass', \n",
    "                     'bass.wav', 'lead.wav', 'pluck.wav',\n",
    "                     'c.wav', 'd.wav', 'e.wav', 'f.wav', 'g.wav', 'a.wav', 'b.wav', \n",
    "                     'c#.wav', 'd#.wav', 'e#.wav', 'f#.wav', 'g#.wav', 'a#.wav', 'b#.wav'\n",
    "                     'C.wav', 'D.wav', 'E.wav', 'F.wav', 'G.wav', 'A.wav', 'B.wav',\n",
    "                     'C#.wav', 'D#.wav', 'E#.wav', 'F#.wav', 'G#.wav', 'A#.wav', 'B#.wav',\n",
    "                     'c', 'd', 'e', 'f', 'g', 'a', 'b', \n",
    "                     'c#', 'd#', 'e#', 'f#', 'g#', 'a#', 'b#v'\n",
    "                     'C', 'D', 'E', 'F', 'G', 'A', 'B',\n",
    "                     'C#', 'D#', 'E#v', 'F#', 'G#', 'A#', 'B#',\n",
    "                     'cmaj.wav', 'dmaj.wav', 'emaj.wav', 'fmaj.wav', 'gmaj.wav', 'amaj.wav', 'bmaj.wav', \n",
    "                     'cmin.wav', 'dmin.wav', 'emin.wav', 'fmin.wav', 'gmin.wav', 'amin.wav', 'bmin.wav',\n",
    "                     'A#maj', 'G#min', 'F#maj','E#maj','E-G.wav','C#maj','.wav','C#min','D#maj','A-B.wav','one','shot','D#min','G#maj','_F#maj_','_F#maj', 'F#maj_','Am','_C#maj']\n",
    "    exclude_words = [word.lower() for word in exclude_words]\n",
    "    description = ' '.join([word for word in etc.split() if word.lower() not in exclude_words and not any(char.isdigit() for char in word)])\n",
    "\n",
    "    description = description.replace('.wav', '').lower()\n",
    "\n",
    "    return artist, instrument, key, is_one_shot, description\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_csv(csv_file_path, wav_folder_path):\n",
    "    with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['File_Name', 'Artist', 'Instrument', 'Etc', 'Words'])\n",
    "\n",
    "        for file in os.listdir(wav_folder_path):\n",
    "            if file.endswith('.wav'):\n",
    "                artist, instrument, key, is_one_shot, description = parse_filename(file)\n",
    "                etc = ' '.join([str(key), 'one_shot' if is_one_shot else ''])\n",
    "\n",
    "                # the filename to lowercase\n",
    "                file = file.lower()\n",
    "\n",
    "                # Only write rows with no empty columns\n",
    "                if all([file, artist, instrument, etc, description]):\n",
    "                    csv_writer.writerow([file, artist, instrument, etc, description])\n",
    "\n",
    "\n",
    "def gather_files(csv_file_path, src_folder_path, dst_folder_path):\n",
    "    if not os.path.exists(dst_folder_path):\n",
    "        os.makedirs(dst_folder_path)\n",
    "\n",
    "    with open(csv_file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        for row in csv_reader:\n",
    "            filename = row['File_Name']\n",
    "            src_file = os.path.join(src_folder_path, filename)\n",
    "            dst_file = os.path.join(dst_folder_path, filename)\n",
    "\n",
    "            if os.path.exists(src_file):\n",
    "                shutil.copy2(src_file, dst_file)\n",
    "\n",
    "\n",
    "csv_file_path = 'synthsoundoutput5.csv'\n",
    "wav_folder_path = \"/Users/butterflyeffectleedea/desktop/git/Aiffel/soundsprayaiffelsynth\"\n",
    "dst_folder_path = \"/Users/butterflyeffectleedea/desktop/git/Aiffel/selected_sounds\"\n",
    "\n",
    "create_csv(csv_file_path, wav_folder_path)\n",
    "gather_files(csv_file_path, wav_folder_path, dst_folder_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wav to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV to JSON\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_name = \"synthsoundoutput5.csv\"\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "# A 열의 인덱스를 사용하여 각 행을 JSON 파일로 저장\n",
    "for index, row in df.iterrows():\n",
    "    row_data = {key: [value] for key, value in row.items()}  \n",
    "    a_value = row[df.columns[0]]  \n",
    "    a_value_without_ext = os.path.splitext(a_value)[0]  # \".wav\" 부분을 제거\n",
    "    json_file_name = f\"{a_value_without_ext}.json\"  # 파일 이름으로 사용\n",
    "\n",
    "    # JSON 파일 저장\n",
    "    with open(json_file_name, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(row_data, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "\n",
    "def split_csv(input_csv_path, output_csv_1_path, output_csv_2_path, ratio=0.1):\n",
    "    # Separate rows based on instrument\n",
    "    rows_by_instrument = {'lead': [], 'bass': [], 'pluck': []}\n",
    "\n",
    "    with open(input_csv_path, newline='', encoding='utf-8') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        for row in csv_reader:\n",
    "            instrument = row['Instrument']\n",
    "            if instrument in rows_by_instrument:\n",
    "                rows_by_instrument[instrument].append(row)\n",
    "\n",
    "    # Randomly sample rows from each instrument category\n",
    "    sampled_rows = {'lead': [], 'bass': [], 'pluck': []}\n",
    "    remaining_rows = {'lead': [], 'bass': [], 'pluck': []}\n",
    "\n",
    "    for instrument, rows in rows_by_instrument.items():\n",
    "        sample_size = int(len(rows) * ratio)\n",
    "        sampled_rows[instrument] = random.sample(rows, sample_size)\n",
    "        remaining_rows[instrument] = [row for row in rows if row not in sampled_rows[instrument]]\n",
    "\n",
    "    # Write sampled rows and remaining rows to separate CSV files\n",
    "    def write_rows_to_csv(output_csv_path, rows_dict):\n",
    "        with open(output_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            csv_writer = csv.writer(csvfile)\n",
    "            csv_writer.writerow(['File_Name', 'Artist', 'Instrument', 'Etc', 'Words'])\n",
    "\n",
    "            for instrument, rows in rows_dict.items():\n",
    "                for row in rows:\n",
    "                    csv_writer.writerow([row['File_Name'], row['Artist'], row['Instrument'], row['Etc'], row['Words']])\n",
    "\n",
    "    write_rows_to_csv(output_csv_1_path, sampled_rows)\n",
    "    write_rows_to_csv(output_csv_2_path, remaining_rows)\n",
    "\n",
    "\n",
    "input_csv_path = 'synthsoundoutput5.csv'\n",
    "output_csv_1_path = 'stest_10_percent.csv'\n",
    "output_csv_2_path = 'strain_90_percent.csv'\n",
    "\n",
    "split_csv(input_csv_path, output_csv_1_path, output_csv_2_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find train and test wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "csv_file_path = 'stest_10_percent.csv'\n",
    "wav_folder_path = \"/Users/butterflyeffectleedea/desktop/git/Aiffel/soundsprayaiffelsynth\"\n",
    "dst_folder_path = \"/Users/butterflyeffectleedea/desktop/git/Aiffel/stest\"\n",
    "\n",
    "create_csv(csv_file_path, wav_folder_path)\n",
    "gather_files(csv_file_path, wav_folder_path, dst_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "csv_file_path = 'strain_90_percent.csv'\n",
    "wav_folder_path = \"/Users/butterflyeffectleedea/desktop/git/Aiffel/soundsprayaiffelsynth\"\n",
    "dst_folder_path = \"/Users/butterflyeffectleedea/desktop/git/Aiffel/strain\"\n",
    "\n",
    "create_csv(csv_file_path, wav_folder_path)\n",
    "gather_files(csv_file_path, wav_folder_path, dst_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "def move_wav_files(csv_path, source_folder, destination_folder):\n",
    "    with open(csv_path, newline='', encoding='utf-8') as csvfile:\n",
    "        csv_reader = csv.DictReader(csvfile)\n",
    "        for row in csv_reader:\n",
    "            file_name = row['File_Name']\n",
    "            source_file_path = os.path.join(source_folder, file_name)\n",
    "            destination_file_path = os.path.join(destination_folder, file_name)\n",
    "\n",
    "            if os.path.exists(source_file_path):\n",
    "                shutil.move(source_file_path, destination_file_path)\n",
    "            else:\n",
    "                print(f\"File not found: {source_file_path}\")\n",
    "\n",
    "\n",
    "source_wav_folder_path = \"/Users/butterflyeffectleedea/desktop/git/Aiffel/soundsprayaiffelsynth\"\n",
    "train_destination_folder = \"strain\"\n",
    "test_destination_folder = \"stest\"\n",
    "\n",
    "# Create the destination folders if they don't exist\n",
    "os.makedirs(train_destination_folder, exist_ok=True)\n",
    "os.makedirs(test_destination_folder, exist_ok=True)\n",
    "\n",
    "move_wav_files(output_csv_2_path, source_wav_folder_path, train_destination_folder)\n",
    "move_wav_files(output_csv_1_path, source_wav_folder_path, test_destination_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV to JSON for train and test\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_name = \"stest_10_percent.csv\"\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "# 각 행을 JSON 파일로 저장\n",
    "for index, row in df.iterrows():\n",
    "    row_data = {key: [value] for key, value in row.items()}  \n",
    "    a_value = row[df.columns[0]]  \n",
    "    a_value_without_ext = os.path.splitext(a_value)[0]  # \".wav\" 부분을 제거\n",
    "    json_file_name = f\"{a_value_without_ext}.json\"  # 파일 이름으로 사용\n",
    "\n",
    "    # JSON 저장\n",
    "    with open(json_file_name, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(row_data, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV to JSON\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# CSV 파일 읽기\n",
    "file_name = \"strain_90_percent.csv\"\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "# A 열의 인덱스를 사용하여 각 행을 JSON 파일로 저장\n",
    "for index, row in df.iterrows():\n",
    "    row_data = {key: [value] for key, value in row.items()}  \n",
    "    a_value = row[df.columns[0]]  \n",
    "    a_value_without_ext = os.path.splitext(a_value)[0]  # \".wav\" 부분을 제거\n",
    "    json_file_name = f\"{a_value_without_ext}.json\"  # 파일 이름으로 사용\n",
    "\n",
    "    # JSON 파일 저장\n",
    "    with open(json_file_name, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(row_data, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
