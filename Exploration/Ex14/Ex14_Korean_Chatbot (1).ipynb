{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371e23f4",
   "metadata": {},
   "source": [
    "# 한국어 데이터로 챗봇 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07ac0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e7bc55",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3a8216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = os.getenv('HOME') + '/aiffel/transformer_chatbot/data/ChatbotData .csv'\n",
    "\n",
    "df= pd.read_csv(csv_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22568c21",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 전처리하기\n",
    "\n",
    "영어 데이터와는 전혀 다른 데이터인 만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행해야 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f46956b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11823, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>datatype</th>\n",
       "      <th>null count</th>\n",
       "      <th>null ratio</th>\n",
       "      <th>unique count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>label</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index datatype  null count  null ratio  unique count\n",
       "0      Q   object           0         0.0         11662\n",
       "1      A   object           0         0.0          7779\n",
       "2  label    int64           0         0.0             3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null 확인 >> 없음\n",
    "null = pd.DataFrame(df.dtypes, columns=['datatype'])\n",
    "null = null.reset_index()\n",
    "null['null count'] = df.isnull().sum().values\n",
    "null['null ratio'] = null['null count']/df.shape[0]\n",
    "null['unique count'] = df.nunique().values\n",
    "print(df.shape)\n",
    "null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c303ee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dupli whole': 0, 'dupli Q columns': 161, 'dupli A columns': 4044}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>고양이 키우고 싶어</td>\n",
       "      <td>가족들과 상의해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>공시 준비 힘들어</td>\n",
       "      <td>잘 될 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>돈 벌고 싶어</td>\n",
       "      <td>많이 벌수록 좋아요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>로또 번호 알려줘</td>\n",
       "      <td>알면 제가 하죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>마음이 울적해</td>\n",
       "      <td>거리를 걸어보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11642</th>\n",
       "      <td>착해서 잘해주는 건지 좋아하는 건지</td>\n",
       "      <td>헷갈린다고 말해보세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11649</th>\n",
       "      <td>첫 눈에 반하는게 가능해?</td>\n",
       "      <td>당연히 가능하죠.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11658</th>\n",
       "      <td>첫사랑 생각나</td>\n",
       "      <td>지금의 사랑에 충실하세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11732</th>\n",
       "      <td>커플여행이 나을까 그냥 우리끼리 갈까?</td>\n",
       "      <td>저는 둘이 가는 게 좋아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Q                A  label\n",
       "196               고양이 키우고 싶어     가족들과 상의해보세요.      0\n",
       "235                공시 준비 힘들어         잘 될 거예요.      0\n",
       "1294                 돈 벌고 싶어      많이 벌수록 좋아요.      0\n",
       "1445               로또 번호 알려줘        알면 제가 하죠.      0\n",
       "1481                 마음이 울적해       거리를 걸어보세요.      0\n",
       "...                      ...              ...    ...\n",
       "11642    착해서 잘해주는 건지 좋아하는 건지     헷갈린다고 말해보세요.      2\n",
       "11649         첫 눈에 반하는게 가능해?        당연히 가능하죠.      2\n",
       "11658                첫사랑 생각나   지금의 사랑에 충실하세요.      2\n",
       "11732  커플여행이 나을까 그냥 우리끼리 갈까?  저는 둘이 가는 게 좋아요.      2\n",
       "11819         훔쳐보는 것도 눈치 보임.    훔쳐보는 거 티나나봐요.      2\n",
       "\n",
       "[161 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복확인 >> 전체중복 없음, 칼럼중복 : 161, 4044개 >> 중복 드롭 니니함\n",
    "dupli = {}\n",
    "dupli['dupli whole'] = df.duplicated().sum()\n",
    "dupli['dupli Q columns'] = df.duplicated(subset=['Q']).sum()\n",
    "dupli['dupli A columns'] = df.duplicated(subset=['A']).sum()\n",
    "dupli_Q = df[df.duplicated(subset=['Q'])]\n",
    "dupli_A = df[df.duplicated(subset=['A'])]\n",
    "print(dupli)\n",
    "dupli_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76974f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SD카드 안돼</td>\n",
       "      <td>다시 새로 사는 게 마음 편해요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n",
       "      <td>시간을 정하고 해보세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>가끔 뭐하는지 궁금해</td>\n",
       "      <td>그 사람도 그럴 거예요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>가스불 켜놓고 나온거 같아</td>\n",
       "      <td>빨리 집에 돌아가서 끄고 나오세요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11806</th>\n",
       "      <td>혼자만 설레고 혼자서 끝내는 짝사랑 그만할래.</td>\n",
       "      <td>맘고생 많았어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11807</th>\n",
       "      <td>화이트데이에 고백할까요?</td>\n",
       "      <td>선물을 주면서 솔직하고 당당하게 고백해보세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11809</th>\n",
       "      <td>확실히 날 좋아하는 걸 아는 남자랑 친구가 될 수 있을까?</td>\n",
       "      <td>그 사람을 위해서는 그러면 안돼요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11816</th>\n",
       "      <td>회식하는데 나만 챙겨줘. 썸임?</td>\n",
       "      <td>호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4044 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Q                                    A  \\\n",
       "3                       3박4일 정도 놀러가고 싶다                          여행은 언제나 좋죠.   \n",
       "6                               SD카드 안돼                   다시 새로 사는 게 마음 편해요.   \n",
       "9                     SNS 시간낭비인데 자꾸 보게됨                        시간을 정하고 해보세요.   \n",
       "12                          가끔 뭐하는지 궁금해                        그 사람도 그럴 거예요.   \n",
       "18                       가스불 켜놓고 나온거 같아                  빨리 집에 돌아가서 끄고 나오세요.   \n",
       "...                                 ...                                  ...   \n",
       "11806         혼자만 설레고 혼자서 끝내는 짝사랑 그만할래.                            맘고생 많았어요.   \n",
       "11807                     화이트데이에 고백할까요?            선물을 주면서 솔직하고 당당하게 고백해보세요.   \n",
       "11809  확실히 날 좋아하는 걸 아는 남자랑 친구가 될 수 있을까?                  그 사람을 위해서는 그러면 안돼요.   \n",
       "11816                 회식하는데 나만 챙겨줘. 썸임?  호감이 있을 수도 있어요. 그렇지만 조금 더 상황을 지켜보세요.   \n",
       "11822                        힘들어서 결혼할까봐                   도피성 결혼은 하지 않길 바라요.   \n",
       "\n",
       "       label  \n",
       "3          0  \n",
       "6          0  \n",
       "9          0  \n",
       "12         0  \n",
       "18         0  \n",
       "...      ...  \n",
       "11806      2  \n",
       "11807      2  \n",
       "11809      2  \n",
       "11816      2  \n",
       "11822      2  \n",
       "\n",
       "[4044 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupli_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb6e41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n"
     ]
    }
   ],
   "source": [
    "# 샘플 최대갯수 \n",
    "MAX_SAMPLES = df.shape[0]\n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbb8d6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!!', '.?', \"'\", '.!', ';;;', '~~~~', '.!!', ';;', ';?', ',', '….', '~', '!?', '~!!', '??', '~??', '.', '???', '!!!', '%', '?.', ',.', '~~', '~~~', '..', '?', '!', '…', ',,']\n",
      "['!!', '!', '....', '.-', \"',\", '..', \"'\", '.', ',', '?', '~', '-', '…']\n"
     ]
    }
   ],
   "source": [
    "# 쓰여진 모든 특수문자 찾기\n",
    "\n",
    "def used_special_characters(column):\n",
    "    special_characters = df[column].apply(lambda x: re.findall(r'[^\\w\\s]+', x))\n",
    "    unique_special_characters = list(set([item for sublist in special_characters for item in sublist]))\n",
    "    return unique_special_characters\n",
    "\n",
    "print(used_special_characters('Q'))\n",
    "print(used_special_characters('A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a16a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[';;;', '!', '%', '~~~~', '~~', '~~~', \"'\", ';;', '.', ',', '?', '~', '…']\n",
      "['!', '.-', '..', \"'\", '.', ',', '?', '~', '-', '…']\n"
     ]
    }
   ],
   "source": [
    "# 사용할 특수문자만 남기고 클리닝하기\n",
    "\n",
    "def clean_special_characters(column):\n",
    "    df[column] = df[column].apply(lambda x: re.sub(r'[^\\w\\s](?![,!?.]{2,})[,!?.]', '', x))\n",
    "    return df[column]\n",
    "\n",
    "df['Q'] = clean_special_characters('Q')\n",
    "df['A'] = clean_special_characters('A')\n",
    "print(used_special_characters('Q'))\n",
    "print(used_special_characters('A'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6368e3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions shape : (11823,)\n",
      "answers shape : (11823,)\n"
     ]
    }
   ],
   "source": [
    "# inputs, outputs 정하기\n",
    "\n",
    "questions = df['Q'].values\n",
    "answers = df['A'].values\n",
    "\n",
    "print(\"questions shape :\",questions.shape)\n",
    "print(\"answers shape :\",answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7be7051d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 11650번째 질문 샘플: 첫 눈에 반하는게 가능해?\n",
      "전처리 후의 11650번째 답변 샘플: 당연히 가능하죠.\n",
      "챗봇 너무 똑똑이! 난 너한테 반함!\n"
     ]
    }
   ],
   "source": [
    "print('전처리 후의 11650번째 질문 샘플: {}'.format(questions[11649]))\n",
    "print('전처리 후의 11650번째 답변 샘플: {}'.format(answers[11649]))\n",
    "print('챗봇 너무 똑똑이! 난 너한테 반함!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3457beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "    # student와 온점 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6937c96e",
   "metadata": {},
   "source": [
    "# Step 3. SubwordTextEncoder 사용하기\n",
    "\n",
    "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있습니다. 하지만 여기서는 형태소 분석기가 아닌 위 실습에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용해보세요.\n",
    "\n",
    "- TensorFlow Datasets SubwordTextEncoder 를 토크나이저로 사용한다. 단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고, 각 토큰을 고유한 정수로 인코딩 한다.\n",
    "- 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가한다.\n",
    "- 최대 길이 MAX_LENGTH 인 40을 넘는 문장들은 필터링한다.\n",
    "- MAX_LENGTH보다 길이가 짧은 문장들은 40에 맞도록 패딩 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd164612",
   "metadata": {},
   "source": [
    ">## 1) 단어장(Vocabulary) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e79ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q, A Vocabulary 생성\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=8359)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849af44",
   "metadata": {},
   "source": [
    "The purpose of the tokenizer is to convert a string of text into a sequence of tokens, where each token is a numerical representation of a word or subword unit. The SubwordTextEncoder class uses a subword tokenization method, which means it can split words into subword units, making the tokenization process more robust and less prone to out-of-vocabulary (OOV) tokens. The build_from_corpus method trains the tokenizer on the provided text data and creates the vocabulary.  \n",
    "\n",
    "The 2^13 means 2 raised to the power of 13, or 2 to the 13th power. It is used as the target_vocab_size argument for the SubwordTextEncoder.build_from_corpus method.  \n",
    "The target_vocab_size argument is used to determine the number of tokens to be used in the encoding. In this case, a vocabulary size of 2^13 tokens is chosen. The choice of vocabulary size depends on the complexity of the data being processed and the desired balance between compression and accuracy.  \n",
    "By using a smaller vocabulary size, you can reduce the amount of memory required to store the encoding and speed up processing time, but you may also lose information and accuracy in the encoding. Conversely, a larger vocabulary size may provide more accurate encodings but will require more memory and processing time.  \n",
    "In this example, the choice of 2^13 as the vocabulary size is arbitrary and may or may not be appropriate for your specific use case. You may want to experiment with different vocabulary sizes to see what works best for your specific data and requirements. (answered by chatopenai)                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bdfdde",
   "metadata": {},
   "source": [
    "<mark> 2**13 >> 8359로 revised </mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a34d923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수 부여\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d75f174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8357]\n",
      "END_TOKEN의 번호 : [8358]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "266ee331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB_SIZE : 8359\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2 를 하여 VOCAB_SIZE\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print('VOCAB_SIZE :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98329af",
   "metadata": {},
   "source": [
    ">## 2. 각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)\n",
    "위에서 tensorflow_datasets의 SubwordTextEncoder를 사용해서 tokenizer를 정의하고 Vocabulary를 만들었다면, tokenizer.encode()로 각 단어를 정수로 변환할 수 있고 또는 tokenizer.decode()를 통해 정수 시퀀스를 단어 시퀀스로 변환할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba42a93e",
   "metadata": {},
   "source": [
    ">>### 2-1. Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "630b2be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 11650번째 질문 샘플: 첫 눈에 반하는게 가능해?\n",
      "전처리 후의 11650번째 답변 샘플: 당연히 가능하죠.\n",
      "정수 인코딩 후의 11650번째 질문 샘플: [1604, 1442, 378, 432, 3770, 8164]\n",
      "정수 인코딩 후의 11650번째 답변 샘플: [4481, 8071, 8147]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 11650번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('전처리 후의 11650번째 질문 샘플: {}'.format(questions[11649]))\n",
    "print('전처리 후의 11650번째 답변 샘플: {}'.format(answers[11649]))\n",
    "print('정수 인코딩 후의 11650번째 질문 샘플: {}'.format(tokenizer.encode(questions[11649])))\n",
    "print('정수 인코딩 후의 11650번째 답변 샘플: {}'.format(tokenizer.encode(answers[11649])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97632b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 인코딩 한 값 디코딩해서 결과 확인해보기\n",
    "\n",
    "# def idx_to_text(element):\n",
    "#     encoded_example = tokenizer.encode(element)\n",
    "#     decoded_example = [tokenizer.decode([token]) for token in encoded_example]\n",
    "#     print(\"해당값 디코딩 결과: \\n\".format(element))\n",
    "#     for i, token in enumerate(encoded_example):\n",
    "#         print(\"{} : {}\".format(token, decoded_example[i]))\n",
    "    \n",
    "# idx_to_text(questions[11649])      \n",
    "# idx_to_text(answers[11649])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f423ccf",
   "metadata": {},
   "source": [
    ">>### 2-2. Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e473938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions 최소 길이 : 1\n",
      "questions 최대 길이 : 15\n",
      "questions 평균 길이 : 3.5872452000338324\n",
      "answers 최소 길이 : 1\n",
      "answers 최대 길이 : 21\n",
      "answers 평균 길이 : 3.6936479742874058\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "questions_len = [len(s.split()) for s in df['Q']]\n",
    "answers_len = [len(s.split()) for s in df['A']]\n",
    "\n",
    "print('questions 최소 길이 : {}'.format(np.min(questions_len)))\n",
    "print('questions 최대 길이 : {}'.format(np.max(questions_len)))\n",
    "print('questions 평균 길이 : {}'.format(np.mean(questions_len)))\n",
    "print('answers 최소 길이 : {}'.format(np.min(answers_len)))\n",
    "print('answers 최대 길이 : {}'.format(np.max(answers_len)))\n",
    "print('answers 평균 길이 : {}'.format(np.mean(answers_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(questions_len)\n",
    "plt.title('questions')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(answers_len)\n",
    "plt.title('answers')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('questions')\n",
    "plt.hist(questions_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('answers')\n",
    "plt.hist(answers_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c5556ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터의 몇프로인지 계산하는 함수\n",
    "\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s.split()) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "43f63328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 40 이하인 샘플의 비율: 1.0\n",
      "전체 샘플 중 길이가 40 이하인 샘플의 비율: 1.0\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 40\n",
    "below_threshold_len(MAX_LENGTH, df['Q'])\n",
    "below_threshold_len(MAX_LENGTH,  df['A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ececcd",
   "metadata": {},
   "source": [
    "<mark> 처음에 80% 정도만 하려고 조정을 하다가,, 데이터도 너무 적고, 최대 길이도 얼마되지 않아서 그냥 넉넉한 최대치로 lms와 동일하게 40을 줬다. <\\mark> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76a98dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거 & 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 이하인 경우에만 데이터셋으로 허용\n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "\n",
    "    # 최대 길이로 모든 데이터셋을 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9088718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60f842c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8359\n",
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "780e9b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[8357 1604 1442  378  432 3770 8164 8358    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(type(questions))\n",
    "print(questions[11649])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8e97c",
   "metadata": {},
   "source": [
    ">## 3. 교사 강요(Teacher Forcing)  \n",
    "\n",
    "트랜스포머는 인코더, 디코더 모두 교사 강요(Teacher Forcing) 를 적용합니다.\n",
    "교사 강요를 적용하기 위해서 위 샘플을 디코더의 입력과 레이블로 사용한다고 하였을 때, 각각 어떻게 수정해서 입력과 레이블로 사용해야 할까요?  \n",
    "질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성합니다. \n",
    "\n",
    "이때, 교사 강요를 위해서 answers[:, :-1]를 디코더의 입력값, answers[:, 1:]를 디코더의 레이블로 사용합니다.  \n",
    "입력 : \\<START_TOKEN> I AM A STUDENT \\<END_TOKEN> \\<PAD> \\<PAD> \\<PAD>  \n",
    "레이블 : I AM A STUDENT \\<END_TOKEN> \\<PAD> \\<PAD> \\<PAD> \\<PAD>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "058a94f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8357 8096 1530 3058 8134 8358    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "(11823, 40)\n"
     ]
    }
   ],
   "source": [
    "# questions 형태 확인하기\n",
    "print(questions[0])\n",
    "print(questions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb3ef0f",
   "metadata": {},
   "source": [
    "그 전 모델에서는 model.fit할 때,\n",
    "    \n",
    "    - x : encoder_input_train, decoder_input_train(인코터 어텐션과 인풋 받아서 학습시켜 예측을 통해 예상 타겟값)\n",
    "    - y : decoder_target_train 을 넣어서 그 둘의 accuracy를 비교했다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe5980",
   "metadata": {},
   "source": [
    "하지만 Transformer decoder 만들 때는,  \n",
    "\n",
    "- 입력 : \\<START_TOKEN> I AM A STUDENT \\<END_TOKEN> \\<PAD> \\<PAD> \\<PAD>  \n",
    "- 레이블 : I AM A STUDENT \\<END_TOKEN> \\<PAD> \\<PAD> \\<PAD> \\<PAD>  \n",
    "\n",
    "이렇게 되어야 하므로,\n",
    "- decoder_input은 뒤에 pad 하나 떼도록 [:,:-1]로 슬라이싱하고,  \n",
    "- decoder_output은 앞에 start_token 떼도록 [:,1:]로 슬라이싱한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f902fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8357 3842   69 8075 8147 8358    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "(11823, 40)\n"
     ]
    }
   ],
   "source": [
    "# 슬라이싱 전에 answers 형태 확인하고\n",
    "print(answers[0])\n",
    "print(answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0089d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer decoder에 쓸 input, output으로 슬라이싱 해주기\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {'inputs': questions,\n",
    "     'dec_inputs': answers[:, :-1]},\n",
    "    \n",
    "    {'outputs': answers[:, 1:]},\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6237da0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ({inputs: (None, 40), dec_inputs: (None, 39)}, {outputs: (None, 39)}), types: ({inputs: tf.int32, dec_inputs: tf.int32}, {outputs: tf.int32})>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a4c223",
   "metadata": {},
   "source": [
    "# Step 4. 모델 구성하기\n",
    "\n",
    "![2.PNG](2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be583c4",
   "metadata": {},
   "source": [
    "# Transfer 구현시 만들어야하는 함수들  \n",
    "\n",
    "#### A. Attention layer 만들어 준비하기  \n",
    "1. positional encoding  \n",
    "2. Multi heads Self Attiention   \n",
    "    2-1. Scaled Dot Product   \n",
    "    2-2. Mask 함수 2개  \n",
    "    \n",
    "#### B. 인코더   \n",
    "1. 인코더 한개 블럭 만들기  \n",
    "2. 인코더 블럭 여러개 쌓기  \n",
    "\n",
    "#### C. 디코더  \n",
    "1. 디코더 한개 블럭 만들기  \n",
    "2. 디코더 블럭 여러개 쌓기  \n",
    "\n",
    "#### D. 트랜스포머 구현하기  \n",
    "1. 하이퍼 파라미터  \n",
    "2. 손실함수  \n",
    "3. 학습률  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dba8d0",
   "metadata": {},
   "source": [
    ">## A. Attention layer 만들어 준비하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "994fab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. positional encoding\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        # 각도 배열 생성\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "        pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "        pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "        pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d16b01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-1. in Self Attention layer\n",
    "\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \n",
    "    # 1.어텐션 가중치는 Q와 K의 닷 프로덕트 = 어텐션 스코어 행렬 = 어텐션에너지\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # 2.가중치를 정규화 & dk의 루트값으로 나눠준다\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # 2-3.패딩에 마스크 추가\n",
    "    # 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "    # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # 3.softmax적용 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "    # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    # 4.최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "    # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "    return output\n",
    "\n",
    "# output : (batch_size, num_heads, seq_len_q, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "661956b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 멀티헤드 어텐션 함수 (스케일드 닷 프로덕트 어텐션 함수도 안에 포함됨)\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        ## 2-3 사이에 멀티헤드할 준비작업들\n",
    "        # Q,K,V 지정 후 d_model 전체차원을 통과시켜서(가중치W 곱해서) WQ,WK,Wv로 정의\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model) # Q 지정 \n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)   # K 지정\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model) # V 지정\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "    def split_heads(self, inputs, batch_size): # 나눌 헤드수와 reshape\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3]) # 전치시키는것\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "        \n",
    "        # 1. WQ, WK, WV에 해당하는 밀집층 지나기 (W : 실질적가중치)\n",
    "        # q : (batch_size, query의 문장 길이, d_model)\n",
    "        # k : (batch_size, key의 문장 길이, d_model)\n",
    "        # v : (batch_size, value의 문장 길이, d_model)\n",
    "        # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "\n",
    "        # Q, K, V에 각각 Dense를 적용합니다\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "        \n",
    "#################################################################################\n",
    "        \n",
    "        # 1-2 사이. 헤드 나누기\n",
    "        # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "        # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "        \n",
    "        # 병렬 연산을 위해 머리만큼 Q,K,V 나눠주기\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    " #################################################################################\n",
    "\n",
    "        # 2-4. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "        # 2.일정수로 나눠서 정규화하고,\n",
    "        # 2-3.(필요하면 mask 씌워서 값 무시하게 해주고,)\n",
    "        # 3.Softmax로 0-1사이의 확률값으로 바꾸고\n",
    "        # 4.V 곱해서 최종 어텐션값 구하기\n",
    "        # output = (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "        \n",
    " #################################################################################\n",
    "\n",
    "        # 5. 행렬곱 전에 순서를 맞춰서 transpose해주기\n",
    "        # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    " #################################################################################\n",
    "    \n",
    "        # 6. 헤드 연결(concatenate)하기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "#################################################################################\n",
    "\n",
    "        # 7. WO에 해당하는 dense층 지나기\n",
    "        # (batch_size, query의 문장 길이, d_model)\n",
    "        # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf0b3bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-2. Mask 함수 1\n",
    "\n",
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab060675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-2. Mask 함수 2\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418ce22b",
   "metadata": {},
   "source": [
    ">## B. 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c02a034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 인코더 한개 블럭 만들기\n",
    "\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 사용\n",
    "    # 인코더의 입력으로 들어가는 문장에는 0패딩이 있을 수 있으므로, \n",
    "    # 어텐션 시 패딩 토큰을 제외하도록 패딩 마스크를 사용합니다.\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 1. 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "    attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "    \n",
    "    # 1-2. 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "    \n",
    "    # 2. 포지션 와이즈 FFNN 레이어\n",
    "    # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    \n",
    "    # 2-2. 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f16ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 인코더 블럭 여러개 쌓기\n",
    "\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "    # 패딩 마스크 준비 (디코더와 달리 단순히 0으로 붙은것만 가리는 것)\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    # 0-1. 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 0-2. 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings) #앞서 만든 클래스\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    # 인코더를 num_layers개 쌓기 (논문에서는 6개)\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506bf5d",
   "metadata": {},
   "source": [
    ">## C. 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e67ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 디코더 한개 블럭 만들기  \n",
    "\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    \n",
    "    # 룩어헤드 마스크(첫번째 서브층) 준비\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    # 패딩 마스크(두번째 서브층) 준비\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 1. 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "    attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask ## 중요! 룩어헤드 마스크\n",
    "      })\n",
    "\n",
    "    # 1-2. 잔차 연결과 층 정규화\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    # 2. 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "    attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask  # 패딩 마스크\n",
    "      })\n",
    "\n",
    "    # 2-2. 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    # 3. 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "    # 3-2. 드롭아웃 + 잔차 연결과 층 정규화\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12eba4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 디코더 블럭 여러개 쌓기  \n",
    "\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "\n",
    "    # 인코더 아웃풋을 인풋으로 넣어주고 (인코더랑 다른점)\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    \n",
    "    # 룩어헤드 마스크 준비 (인코더랑 다른점)\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "    # 패딩 마스크준비 (인코더는 이것만 썼음)\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    # 0-1. 임베딩 레이어\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "    # 0-2. 포지셔널 인코딩 + 드롭아웃\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463af70a",
   "metadata": {},
   "source": [
    ">## D. 트랜스포머 구현하기  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c95ab0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    \n",
    "    # 인코더의 입력\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    # 디코더의 입력\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "    \n",
    "#######################################################\n",
    "    \n",
    "    # 인코더의 패딩 마스크 준비\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "    # 디코더의 룩어헤드 마스크(첫번째 서브층) 준비\n",
    "    # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "    # 디코더의 패딩 마스크(두번째 서브층) 준비\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "#######################################################\n",
    "\n",
    "    # 인코더\n",
    "    # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "    enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "#######################################################\n",
    "\n",
    "    # 디코더\n",
    "    # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "    dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "#######################################################\n",
    "\n",
    "    # 완전연결층\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff9b7b",
   "metadata": {},
   "source": [
    "num_layers, d-Model, units는 전부 사용자가 정할 수 있는 하이퍼파라미터 값입니다.  \n",
    "논문에서 num_layers는 6, d-Model은 512였지만, 빠르고 원활한 훈련을 위해 여기서는 각 하이퍼파라미터를 논문에서보다는 작은 값을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ca6bced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    3194112     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    3721472     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8359)   2148263     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,063,847\n",
      "Trainable params: 9,063,847\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 1. 하이퍼 파라미터 \n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed76e2",
   "metadata": {},
   "source": [
    "레이블인 시퀀스에 패딩이 되어 있으므로, loss를 계산할 때 패딩 마스크를 적용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42834d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 손실함수 \n",
    "\n",
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ab3790",
   "metadata": {},
   "source": [
    "딥러닝 모델학습 시 learning rate는 매우 중요한 하이퍼파라미터입니다. 최근에는 모델학습 초기에 learning rate를 급격히 높였다가, 이후 train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법을 널리 사용하고 있습니다. 이런 방법을 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)이라고 합니다.  \n",
    "논문에 나온 공식을 참고하여 커스텀 학습률 스케줄러를 통한 아담 옵티마이저를 사용합니다. 논문에 나온 공식은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "520f3764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 학습률 \n",
    "\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7514a43",
   "metadata": {},
   "source": [
    "그러면 방금 정의한 커스텀 학습률 스케줄링 계획을 시각화해 봅시다. 위에 언급한 수식은 두 부분 중 중 작은 쪽을 택하도록 되어 있습니다. 그래서 학습 초기에는 learning_rate가 step_num에 비례해서 증가하다가 이후로는 감소하는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d8de9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491cbe9c",
   "metadata": {},
   "source": [
    "# Step 5. 모델 컴파일\n",
    "\n",
    "손실 함수와 커스텀 된 학습률(learning rate)을 사용하여 모델을 컴파일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e65dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3f73c3",
   "metadata": {},
   "source": [
    "# Step 6. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5591a9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 16s 53ms/step - loss: 1.4619 - accuracy: 0.0245\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 1.1818 - accuracy: 0.0496\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 10s 53ms/step - loss: 1.0054 - accuracy: 0.0507\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.9292 - accuracy: 0.0546\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.8707 - accuracy: 0.0576\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 10s 54ms/step - loss: 0.8132 - accuracy: 0.0614\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.7482 - accuracy: 0.0675\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.6764 - accuracy: 0.0752\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.5973 - accuracy: 0.0838\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 10s 55ms/step - loss: 0.5148 - accuracy: 0.0932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5af0345d60>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c907c006",
   "metadata": {},
   "source": [
    "# Step 7. 예측 모델 (인퍼런스 모델) 만들어 예측하기\n",
    "\n",
    "예측(inference) 단계는 기본적으로 다음과 같은 과정을 거칩니다.\n",
    "\n",
    "1. 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다. \n",
    "2. 입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다. \n",
    "3. 패딩 마스킹과 룩 어헤드 마스킹을 계산한다. \n",
    "4. 디코더는 입력 시퀀스로부터 다음 단어를 예측한다. \n",
    "5. 디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다. \n",
    "6. END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3f75b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "    # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "    sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "    # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "        predictions = predictions[:, -1:, :]\n",
    "\n",
    "        # 현재 예측한 단어의 정수\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6bf10f",
   "metadata": {},
   "source": [
    "# Step 8. 테스트 해보기\n",
    "\n",
    "임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48185e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "    prediction = decoder_inference(sentence)\n",
    "\n",
    "    # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('입력 : {}'.format(sentence))\n",
    "    print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d175ba68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 이름이 뭐야?\n",
      "출력 : 직접 물어보세요.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'직접 물어보세요.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('이름이 뭐야?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "279364c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 돼지야??\n",
      "출력 : 저도 좋아해요.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저도 좋아해요.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('나 돼지야??')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "424089c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 어떻게 하면 너만큼 똑똑해질 수 있니??\n",
      "출력 : 저도 좋아해요.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저도 좋아해요.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('어떻게 하면 너만큼 똑똑해질 수 있니??')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3744294f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 날 왜 좋아한다고 하는거야?\n",
      "출력 : 직접 물어보세요.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'직접 물어보세요.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('날 왜 좋아한다고 하는거야?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "336c4800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 속상하다ㅠㅠㅠ 왜 내 말을 못알아듣는거야ㅠㅠ\n",
      "출력 : 잘 지내고 있을 거예요.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 지내고 있을 거예요.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('속상하다ㅠㅠㅠ 왜 내 말을 못알아듣는거야ㅠㅠ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cd207cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 쉬운거 물어볼께\n",
      "출력 : 잘 지내고 있을 거예요.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 지내고 있을 거예요.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('쉬운거 물어볼께')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d04b155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 제일 인기있는 한국 음식이 뭐야?\n",
      "출력 : 직접 물어보세요.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'직접 물어보세요.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('제일 인기있는 한국 음식이 뭐야?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5caacdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 힝ㅠㅠ 너랑 안놀아!\n",
      "출력 : 마세요.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'마세요.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('힝ㅠㅠ 너랑 안놀아!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f43ca",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "## 입력 : 힝ㅠㅠ 너랑 안놀아!\n",
    "## 출력 : 마세요.\n",
    "\n",
    "ㅋㅋㅋㅋㅋㅋ  \n",
    "너무 웃겨서 한참 웃었다. 이정도면 훌륭한 챗봇 아닙니까?! ㅋㅋㅋㅋ  \n",
    "seq2seq보다는 오히려 구조가 쉬운것 같다.  \n",
    "제목처럼 Attention all you need 과 확실하다  \n",
    "\n",
    "엄청 어려웠지만 너무 재밌는 과제였다.  \n",
    "이 과제를 하는데 3일을 새벽까지 보고 있었다.  \n",
    "그 덕에 책도 볼 수 있었고, 자료들도 많이 찾아보게 되었다.  \n",
    "내가 상대적으로 약하다고 생각하는 파이썬 코드구현은 openAI가 많이 도와줬고,  \n",
    "조금 더 과정을 견고히 하기 위해 책을 참고하였다.  \n",
    "그리고 케창딥을 하며 조금씩 읽어뒀던 부분들이 생각이 나기도 했다.  \n",
    "점점 재밌어지는 느낌이다.  \n",
    "잠을 못자서 어지럽긴 하지만,,   \n",
    "중수와 하수를 구분하는 기준이 트랜스포머라고 했던 근철님 말씀이 생각나서  \n",
    "그냥 끝까지 해보려 버텼다.  \n",
    "NLP의 주요 모델들을 세 개 정도 구현해 본 것 같은데,  \n",
    "이 기회가 너무 좋았고, 유익한 것 같다.   \n",
    "\n",
    "### 어려웠던 점\n",
    "1. Embedding + Positional vector 만드는 과정  \n",
    "2. Multi head self attention 함수 안에 scaled dot 이 들어갈 때 작업 순서  \n",
    "3. Self attention 작동 순서 이해하는 것\n",
    "4. 정규표현식\n",
    "\n",
    "### 참고  \n",
    "Attention is All You Need https://arxiv.org/abs/1706.03762  \n",
    "https://www.sciencedirect.com/science/article/abs/pii/S092523122100477X  \n",
    "https://lilianweng.github.io/posts/2018-06-24-attention/  \n",
    "https://velog.io/@idj7183/Attention-TransformerSelf-Attention  \n",
    "https://medium.com/platfarm/%EC%96%B4%ED%85%90%EC%85%98-  %EB%A9%94%EC%BB%A4%EB%8B%88%EC%A6%98%EA%B3%BC-transfomer-self-attention-842498fd3225  \n",
    "동빈나 유튜브 https://www.youtube.com/@dongbinna  \n",
    "딥러닝을 이용한 지연어 처리 입문 https://wikidocs.net/book/2155  \n",
    "데싸노트의 실전에서 통하는 머신러닝 (권시현 지음)  \n",
    "머신러닝, 딥러닝 문제해결 전략 (신백균 지음)  \n",
    "데이터 분석가가 반드시 알아야 할 모든것 (황세웅 지음)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a06144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
