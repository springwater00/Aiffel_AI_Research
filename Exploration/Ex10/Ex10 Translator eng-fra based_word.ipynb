{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6e720e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import unicodedata\n",
    "import urllib3\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1847007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 33000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac00e2",
   "metadata": {},
   "source": [
    "# 1. 정제, 정규화, 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf199e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2160cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    # 위에서 구현한 함수를 내부적으로 호출\n",
    "    sent = unicode_to_ascii(sent.lower())\n",
    "\n",
    "    # 단어와 구두점 사이에 공백을 만듭니다.\n",
    "    # Ex) \"he is a boy.\" => \"he is a boy .\"\n",
    "    sent = re.sub(r\"([?.!,¿])\", r\" \\1\", sent)\n",
    "\n",
    "    # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 이들을 제외하고는 전부 공백으로 변환합니다.\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "\n",
    "    sent = re.sub(r\"\\s+\", \" \", sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df945003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "\n",
    "    file_path = os.getenv('HOME') + '/aiffel/translator_seq2seq/data/fra.txt'\n",
    "\n",
    "    with open(file_path, \"r\") as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "\n",
    "            # source 데이터와 target 데이터 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "\n",
    "            # source 데이터 전처리\n",
    "            src_line_input = [w for w in preprocess_sentence(src_line).split()]\n",
    "\n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            # 시작, 종료 토큰 넣기\n",
    "            tar_line_input = [w for w in (\"<sos> \" + tar_line).split()]\n",
    "            tar_line_target = [w for w in (tar_line + \" <eos>\").split()]\n",
    "\n",
    "            encoder_input.append(src_line_input)\n",
    "            decoder_input.append(tar_line_input)\n",
    "            decoder_target.append(tar_line_target)\n",
    "\n",
    "            if i == num_samples - 1:\n",
    "                break\n",
    "\n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1377e24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['go', '.'], ['go', '.'], ['go', '.'], ['hi', '.']]\n",
      "[['<sos>', 'va', '!'], ['<sos>', 'marche', '.'], ['<sos>', 'en', 'route', '!'], ['<sos>', 'bouge', '!'], ['<sos>', 'salut', '!']]\n",
      "[['va', '!', '<eos>'], ['marche', '.', '<eos>'], ['en', 'route', '!', '<eos>'], ['bouge', '!', '<eos>'], ['salut', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
    "print(sents_en_in[:5])\n",
    "print(sents_fra_in[:5])\n",
    "print(sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2932bd5",
   "metadata": {},
   "source": [
    "# 2. 토크나이저 (word to index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b4138ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "\n",
    "tokenizer_fra = Tokenizer(filters=\"\", lower=False)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
    "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
    "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d94415fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43f442bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4672, 프랑스어 단어 집합의 크기 : 8137\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
    "print(\"영어 단어 집합의 크기 : {:d}, 프랑스어 단어 집합의 크기 : {:d}\".format(src_vocab_size, tar_vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ceacf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word # 훈련 후 결과 비교할 때 사용\n",
    "\n",
    "tar_to_index = tokenizer_fra.word_index # 훈련 후 예측 과정에서 사용\n",
    "index_to_tar = tokenizer_fra.index_word # 훈련 후 결과 비교할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "980c08a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9320 12232 25453 ... 12268 31402  7778]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdd3c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36eb68e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_of_val = 3000 #33000개 중 3000개를 테스트 데이터로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2095a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bdd4904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 8)\n",
      "(30000, 16)\n",
      "(30000, 16)\n",
      "(3000, 8)\n",
      "(3000, 16)\n",
      "(3000, 16)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7399bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd7011c",
   "metadata": {},
   "source": [
    "# 3. Embedding layer, Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5ed5675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(src_vocab_size, latent_dim)(encoder_inputs) # 임베딩 층\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb) # 패딩 0은 연산에서 제외\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True) # 상태값 리턴을 위해 return_state는 True\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking) # 은닉 상태와 셀 상태를 리턴\n",
    "encoder_states = [state_h, state_c] # 인코더의 은닉 상태와 셀 상태를 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a23bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, latent_dim) # 임베딩 층\n",
    "dec_emb = dec_emb_layer(decoder_inputs) # 패딩 0은 연산에서 제외\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "\n",
    "# 상태값 리턴을 위해 return_state는 True, 모든 시점에 대해서 단어를 예측하기 위해 return_sequences는 True\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "\n",
    "# 인코더의 은닉 상태를 초기 은닉 상태(initial_state)로 사용\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "# 모든 시점의 결과에 대해서 소프트맥스 함수를 사용한 출력층을 통해 단어 예측\n",
    "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb1adf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ee9aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "975cd702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 50)     233600      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     406850      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 50)     0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 50)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50), (None,  20200       masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 50), ( 20200       masking_1[0][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8137)   414987      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,095,837\n",
      "Trainable params: 1,095,837\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0652aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 6s 27ms/step - loss: 0.6163 - acc: 0.8946 - val_loss: 0.8386 - val_acc: 0.8642\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.6115 - acc: 0.8951 - val_loss: 0.8366 - val_acc: 0.8656\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.6076 - acc: 0.8960 - val_loss: 0.8354 - val_acc: 0.8657\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.6037 - acc: 0.8968 - val_loss: 0.8350 - val_acc: 0.8661\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.6000 - acc: 0.8975 - val_loss: 0.8372 - val_acc: 0.8650\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5968 - acc: 0.8982 - val_loss: 0.8347 - val_acc: 0.8661\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5933 - acc: 0.8989 - val_loss: 0.8333 - val_acc: 0.8662\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5903 - acc: 0.8996 - val_loss: 0.8332 - val_acc: 0.8660\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5870 - acc: 0.9003 - val_loss: 0.8311 - val_acc: 0.8669\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5840 - acc: 0.9009 - val_loss: 0.8297 - val_acc: 0.8677\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5807 - acc: 0.9016 - val_loss: 0.8299 - val_acc: 0.8673\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5776 - acc: 0.9022 - val_loss: 0.8333 - val_acc: 0.8665\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5742 - acc: 0.9027 - val_loss: 0.8339 - val_acc: 0.8663\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5711 - acc: 0.9034 - val_loss: 0.8317 - val_acc: 0.8666\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5682 - acc: 0.9036 - val_loss: 0.8282 - val_acc: 0.8662\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5652 - acc: 0.9045 - val_loss: 0.8291 - val_acc: 0.8670\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5620 - acc: 0.9049 - val_loss: 0.8308 - val_acc: 0.8658\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5592 - acc: 0.9053 - val_loss: 0.8305 - val_acc: 0.8667\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5568 - acc: 0.9060 - val_loss: 0.8252 - val_acc: 0.8678\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5542 - acc: 0.9065 - val_loss: 0.8272 - val_acc: 0.8673\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5517 - acc: 0.9070 - val_loss: 0.8271 - val_acc: 0.8670\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5492 - acc: 0.9077 - val_loss: 0.8311 - val_acc: 0.8671\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5471 - acc: 0.9080 - val_loss: 0.8302 - val_acc: 0.8669\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5451 - acc: 0.9085 - val_loss: 0.8313 - val_acc: 0.8674\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5429 - acc: 0.9090 - val_loss: 0.8289 - val_acc: 0.8679\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5410 - acc: 0.9094 - val_loss: 0.8271 - val_acc: 0.8677\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5389 - acc: 0.9098 - val_loss: 0.8267 - val_acc: 0.8673\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5372 - acc: 0.9103 - val_loss: 0.8310 - val_acc: 0.8673\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5352 - acc: 0.9104 - val_loss: 0.8269 - val_acc: 0.8674\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5335 - acc: 0.9108 - val_loss: 0.8299 - val_acc: 0.8663\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5316 - acc: 0.9112 - val_loss: 0.8299 - val_acc: 0.8673\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5297 - acc: 0.9116 - val_loss: 0.8266 - val_acc: 0.8676\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5277 - acc: 0.9117 - val_loss: 0.8314 - val_acc: 0.8668\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5259 - acc: 0.9124 - val_loss: 0.8313 - val_acc: 0.8661\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5241 - acc: 0.9125 - val_loss: 0.8282 - val_acc: 0.8674\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5226 - acc: 0.9128 - val_loss: 0.8293 - val_acc: 0.8674\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5208 - acc: 0.9133 - val_loss: 0.8296 - val_acc: 0.8668\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5190 - acc: 0.9135 - val_loss: 0.8313 - val_acc: 0.8669\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5173 - acc: 0.9138 - val_loss: 0.8287 - val_acc: 0.8671\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5155 - acc: 0.9141 - val_loss: 0.8301 - val_acc: 0.8664\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5139 - acc: 0.9145 - val_loss: 0.8345 - val_acc: 0.8664\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5121 - acc: 0.9148 - val_loss: 0.8330 - val_acc: 0.8667\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5105 - acc: 0.9150 - val_loss: 0.8389 - val_acc: 0.8653\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 6s 27ms/step - loss: 0.5089 - acc: 0.9152 - val_loss: 0.8391 - val_acc: 0.8661\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5073 - acc: 0.9154 - val_loss: 0.8326 - val_acc: 0.8671\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5058 - acc: 0.9157 - val_loss: 0.8316 - val_acc: 0.8666\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5045 - acc: 0.9160 - val_loss: 0.8316 - val_acc: 0.8664\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5030 - acc: 0.9162 - val_loss: 0.8363 - val_acc: 0.8661\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5016 - acc: 0.9165 - val_loss: 0.8318 - val_acc: 0.8663\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.5004 - acc: 0.9167 - val_loss: 0.8384 - val_acc: 0.8659\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 128, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a54199c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더\n",
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2aec6678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더\n",
    "# 이전 시점의 상태를 보관할 텐서\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 훈련 때 사용했던 임베딩 층을 재사용\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 다음 단어 예측을 위해 이전 시점의 상태를 현 시점의 초기 상태로 사용\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# 모든 시점에 대해서 단어 예측\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e762d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4a913c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 정수 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_to_index['<sos>']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    # 구현의 간소화를 위해서 이 함수는 배치 크기를 1로 가정합니다.\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 단어로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "         # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 정해진 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<eos>' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b6ba58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + index_to_src[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_to_index['<sos>']) and i!=tar_to_index['<eos>']):\n",
    "            temp = temp + index_to_tar[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1965db8c",
   "metadata": {},
   "source": [
    "# 4. 모델평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69a86663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  i was late . \n",
      "번역 : j etais en retard . \n",
      "예측 :  j etais en retard . \n",
      "\n",
      "\n",
      "원문 :  he s love struck . \n",
      "번역 : il a le coup de foudre . \n",
      "예측 :  il le chapeau . \n",
      "\n",
      "\n",
      "원문 :  does tom smoke ? \n",
      "번역 : tom fume t il ? \n",
      "예측 :  est ce que tom a mange ? \n",
      "\n",
      "\n",
      "원문 :  they re all guilty . \n",
      "번역 : ils sont tous coupables . \n",
      "예측 :  ils sont toutes froid . \n",
      "\n",
      "\n",
      "원문 :  it looks nice . \n",
      "번역 : ca a l air bien . \n",
      "예측 :  ca a l air bien . \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3,50,100,300,1001]:\n",
    "    input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "    print(\"원문 : \",seq2src(encoder_input_train[seq_index]))\n",
    "    print(\"번역 :\",seq2tar(decoder_input_train[seq_index]))\n",
    "    print(\"예측 :\",decoded_sentence[:-5])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b08a744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  it s not right . \n",
      "번역 : c est inexact . \n",
      "예측 :  ce n est pas a la raison . \n",
      "\n",
      "\n",
      "원문 :  what s your wish ? \n",
      "번역 : quel est votre souhait ? \n",
      "예측 :  quel est votre fils ? \n",
      "\n",
      "\n",
      "원문 :  thanks a lot . \n",
      "번역 : merci mille fois ! \n",
      "예측 :  merci bien . \n",
      "\n",
      "\n",
      "원문 :  we count on you . \n",
      "번역 : nous comptons sur vous . \n",
      "예측 :  nous ne pouvons pas en . \n",
      "\n",
      "\n",
      "원문 :  take it easy ! \n",
      "번역 : relaxe max ! \n",
      "예측 :  ne votre calme ! \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3,50,100,300,1001]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "    print(\"원문 : \",seq2src(encoder_input_test[seq_index]))\n",
    "    print(\"번역 :\",seq2tar(decoder_input_test[seq_index]))\n",
    "    print(\"예측 :\",decoded_sentence[:-5])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc5e9a2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Val', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fc3929",
   "metadata": {},
   "source": [
    "# 5. 회고\n",
    "\n",
    "세상 제일 어려웠던 노드.. 여러자료를 찾아보고 개념은 이해했지만, 코드에서 막혔다. character로 토큰한것을 파라미터값만 지우면 word로 쉽사리 될 것이라고 생각했는데, 중간중간 에러가 떠서 해결이 힘들었다. 참고자료를 보며 복붙하기밖에 안된 것 같아 속상 ㅠㅠㅠㅠ\n",
    "그래프계형은 test에서 loss 가 train보다는 훨씬 높았지만 번역결과는 잘나왔다.\n",
    "참고 : https://wikidocs.net/86900"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7fda72",
   "metadata": {},
   "source": [
    "#### 결과 해석값\n",
    "\n",
    "it s not right  / ce n est pas a la raison. / 그것은 논리가 아니다\n",
    "\n",
    "what s your wish ? / quel est votre fils ? / 당신의 아들은 무엇입니까?\n",
    "\n",
    "thanks a lot . / merci bien . / 감사합니다.\n",
    "\n",
    "we count on you ./ nous ne pouvons pas en ./ 우리는 할 수 없습니다.\n",
    "\n",
    "take it easy ! / ne votre calme ! / 진정하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57e173c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
